import streamlit as st 

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • 
st.set_page_config(
    page_icon = "ğŸ—ºï¸ğŸ“",
    page_title = "BIZBUZZ",
    layout = "wide",
)

st.subheader("USA")

st.markdown("""
    <style>
    .small-font {
        font-size:13px;  # ì›í•˜ëŠ” ê¸€ì í¬ê¸°ë¡œ ì¡°ì ˆ
    }
    </style>
    <p class="small-font"> : CA - NJ - NY - TX - VA - MD - GA - WA - NC 9ê°œì˜ ì£¼ ì„ ì • </p>
    """, unsafe_allow_html=True)

# USA detailed map ë„£ê¸° 
import streamlit as st
import pandas as pd
import plotly.express as px

# ë°ìŠ¤í¬íƒ‘ì— ìˆëŠ” ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
excel_file_path = '/Users/dydit/Desktop/us_address_all.xlsx'  # ì‹¤ì œ ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ ë³€ê²½

# ì—‘ì…€ íŒŒì¼ ì½ì–´ì˜¤ê¸° (ì»¬ëŸ¼ ì´ë¦„ ì—†ìŒ)
df = pd.read_excel(excel_file_path, header=None)

# Scatter_geoë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì¥ì†Œì— í•€ ì°ê¸°
fig = px.scatter_geo(df,
                     lat=df.iloc[:, 1].tolist(),  # ìœ„ë„ ì •ë³´ëŠ” ë‘ ë²ˆì§¸ ì—´ì— ìœ„ì¹˜
                     lon=df.iloc[:, 2].tolist(),  # ê²½ë„ ì •ë³´ëŠ” ì„¸ ë²ˆì§¸ ì—´ì— ìœ„ì¹˜
                     scope='usa',
                     title='DETAILED USA MAP',
                     )

st.plotly_chart(fig, use_container_width=True)

# Colored USA Map ë„£ê¸°
# ì—‘ì…€ íŒŒì¼ì˜ ë¡œì»¬ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”.
excel_file_path = '/Users/dydit/Desktop/us_address_all.xlsx'

# ì—‘ì…€ íŒŒì¼ ì½ì–´ì˜¤ê¸° (ì»¬ëŸ¼ ì´ë¦„ ì—†ìŒ)
df = pd.read_excel(excel_file_path, header=None)

# Scatter_geoë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì¥ì†Œì— í•€ ì°ê¸°
fig = px.scatter_geo(df,
                     lat=df.iloc[:, 1].tolist(),
                     lon=df.iloc[:, 2].tolist(),
                     scope='usa',
                     title='COLORED USA MAP')

# ì£¼ë³„ í•€ì˜ ê°œìˆ˜ ê³„ì‚°
pin_counts = df.iloc[:, 3].value_counts().reset_index()
pin_counts.columns = ['State', 'Pin Count']

# Choropleth mapì„ ì‚¬ìš©í•˜ì—¬ ë¯¸êµ­ ì£¼ì— ëŒ€í•œ í•€ì˜ ê°œìˆ˜ í‘œì‹œ (ë¶‰ì€ ê³„ì—´ ìƒ‰ìƒ ë§µ ì‚¬ìš©)
choropleth_fig = px.choropleth(pin_counts,
                               locations='State',
                               locationmode='USA-states',
                               color='Pin Count',
                               scope='usa',
                               title='Choropleth USA Map - Pin Counts',
                               color_continuous_scale='YlOrRd')

# ë‘ ê·¸ë˜í”„ë¥¼ ë³‘í•©í•˜ê¸°
for trace in choropleth_fig.data:
    fig.add_trace(trace)

# Streamlitì—ì„œ ê·¸ë˜í”„ í‘œì‹œ
st.plotly_chart(fig, use_container_width=True)

# ë°” ì°¨íŠ¸ ìƒì„±
bar_chart_fig = px.bar(pin_counts,
                       x='State',
                       y='Pin Count',
                       title='Pin Counts by States',
                       labels={'Pin Count': 'Count', 'State': 'State'},
                       color_discrete_sequence=['#FF0000'])  # ë¹¨ê°„ìƒ‰ ê³„ì—´ì˜ ìƒ‰ìƒ

# Streamlitì—ì„œ ë°” ì°¨íŠ¸ í‘œì‹œ
st.plotly_chart(bar_chart_fig, use_container_width=True)



# ì½”ë“œ ë³´ì—¬ì¤„ ë•Œ (ì˜ˆì˜ê²Œ)
if st.button("USA python code ë³´ê¸°"):
    code = '''
# ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜ ì •ì˜
def run_code():
    articles = []
    error_list = []

    url_1 = 'https://www.state.gov/press-releases/'
    wd = initialize_chrome_driver()
    wd.get(url_1)
    time.sleep(3)
    html = wd.page_source
    soup = BeautifulSoup(html, 'html.parser')
    error_message = str()
    
    try:
        news_items = soup.find_all('li', class_='collection-result')
        for item in news_items:
            error_message = ''
            link = item.find('a', class_='collection-result__link')['href']
            if not link:
             error_message = Error_Message(error_message, "None Link")
            date_tag = item.find('div', class_='collection-result-meta').find('span', dir='ltr')
            extracted_date = date_tag.text.strip() if date_tag else 'No date found'
            article_date = date_util(extracted_date)
            if not date_tag:
                error_message = Error_Message(error_message, "None date")
            if article_date <= today:
                # newspaper : ì œëª©,ë³¸ë¬¸ ì¶”ì¶œ
                article = Article(link, language='en')
                article.download()
                article.parse()
                title = article.title
                if not title:
                    error_message = Error_Message(error_message, "None Link")
                text = article.text
                if not text:
                    error_message = Error_Message(error_message, "None Content")
                if error_message is not str():
                    error_list.append({
                            'Error Link': url_1,
                            'Error': error_message
                        })
                else:
                    articles.append({
                            'Title': title,
                            'Link': link,
                            'Content(RAW)': text,
                        })
    except Exception as e:
        error_list.append({
            'Error Link': url_1,
            'Error': str(e)
            })
    return articles, error_list
        
# ì½”ë“œ ì‹¤í–‰ 
if st.button("USA python ì½”ë“œ ì‹¤í–‰"):
    # run_code í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê³  ë°˜í™˜ëœ articlesë¥¼ ë°›ìŠµë‹ˆë‹¤.
    articles_data, error_data = run_code()
    
    # ë°˜í™˜ëœ articles ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¼ë¦¿ì˜ dataframeìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    st.dataframe(articles_data)
    '''
    st.code(code, language = "python")

if st.button("run bizbuzz.py"):
    with open('/Users/dydit/Desktop/Final_US_today_GovFin.py', 'r') as file:
        exec(file.read())


# ì˜¤ëŠ˜ ë‚ ì§œë¥¼ 'ì›”ì¼' í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
from datetime import datetime
import streamlit as st
import pandas as pd
today_str = datetime.now().strftime("%m%d") 

# ë²„íŠ¼ê³¼ ë°ì´í„°í”„ë ˆì„ì„ í‘œì‹œí•˜ëŠ” ì½”ë“œ
if st.button("Articles íŒŒì¼ ë³´ê¸°"):
    df_articles = pd.read_csv(f'articles_{today_str}.csv')
    st.dataframe(df_articles)

if st.button("Error List íŒŒì¼ ë³´ê¸°"):
    df_errors = pd.read_csv(f'error_list_{today_str}.csv')
    st.dataframe(df_errors)

if st.button("Final Articles íŒŒì¼ ë³´ê¸°"):
    df_final_articles = pd.read_csv(f'Final Articles_{today_str}.csv')
    st.dataframe(df_final_articles)